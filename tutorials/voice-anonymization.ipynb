{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice anonymization tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T17:36:21.238566Z",
     "start_time": "2023-07-17T17:36:21.237525Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T17:36:21.372284Z",
     "start_time": "2023-07-17T17:36:21.369471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download EmoDB dataset (speech emotion recognition dataset comprises 535 recording spoken in german by 10 actors with 7 emotions)\n",
    "# link: http://emodb.bilderbar.info/index-1280.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import torch\n",
    "import sys\n",
    "import pathlib\n",
    "from speechbrain.utils.metric_stats import EER\n",
    "\n",
    "# Define target folder and script directory paths\n",
    "target_folder = '../tools/audio_representation'\n",
    "script_directory = os.getcwd() \n",
    "target_folder_absolute_path = os.path.join(script_directory, target_folder)\n",
    "# Add target_folder to the system path\n",
    "sys.path.insert(0, target_folder_absolute_path)\n",
    "\n",
    "from audio_representation import AudioRepresentation\n",
    "\n",
    "path_folder = '../tools/voice-anonymization'\n",
    "script_directory = os.getcwd()\n",
    "path_folder_absolute_path = os.path.join(script_directory, path_folder)\n",
    "# adding freeVC_folder to the system path\n",
    "sys.path.insert(0, path_folder_absolute_path)\n",
    "\n",
    "# Import the VoiceAnonymizer class from the anonymizer module\n",
    "from anonymizer import VoiceAnonymizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T17:36:21.540557Z",
     "start_time": "2023-07-17T17:36:21.537892Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_url=\"http://emodb.bilderbar.info/download/download.zip\"\n",
    "data_folder=\"../data/\"\n",
    "dataset_name=\"emodb_dataset\"\n",
    "tool_name=\"coqui\"\n",
    "target_speaker_file_path=\"../data/target_speakers_for_anonymization/timmy_child_narakeet.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=data_folder+dataset_name\n",
    "audio_folder_path = dataset_path + \"/wav/\" \n",
    "anonymized_audio_folder_path = dataset_path + f\"/anonymized_{tool_name}_wav/\" \n",
    "# Set environment variables\n",
    "os.environ['dataset_url'] = dataset_url\n",
    "os.environ['data_folder'] = data_folder\n",
    "os.environ['dataset_name'] = dataset_name\n",
    "os.environ['dataset_path'] = dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T17:36:21.915408Z",
     "start_time": "2023-07-17T17:36:21.907460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:asyncio:Using selector: KqueueSelector\n",
      "emodb_dataset already downloaded in ../data/emodb_dataset.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [ -d \"$dataset_path\" ]; then\n",
    "  echo \"$dataset_name already downloaded in $dataset_path.\"\n",
    "else\n",
    "  echo \"Downloading...\"\n",
    "  mkdir -p \"$dataset_path\"\n",
    "  wget -O \"$dataset_path\"/\"$dataset_name\".zip \"$dataset_url\"\n",
    "  unzip \"$dataset_path\"/\"$dataset_name\".zip -d \"$dataset_path\"\n",
    "  rm \"$dataset_path\"/\"$dataset_name\".zip\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path):\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.pretrained.fetching:Fetch hyperparams.yaml: Using existing file/symlink in /Users/fabiocat/Documents/git/fab/tools/audio_representation/tools/../pretrained_models/speechbrain_spkrec-ecapa-voxceleb/hyperparams.yaml.\n",
      "INFO:speechbrain.pretrained.fetching:Fetch custom.py: Delegating to Huggingface hub, source speechbrain/spkrec-ecapa-voxceleb.\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /speechbrain/spkrec-ecapa-voxceleb/resolve/main/custom.py HTTP/1.1\" 404 0\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /Users/fabiocat/Documents/git/fab/tools/audio_representation/tools/../pretrained_models/speechbrain_spkrec-ecapa-voxceleb.\n",
      "INFO:speechbrain.pretrained.fetching:Fetch embedding_model.ckpt: Using existing file/symlink in /Users/fabiocat/Documents/git/fab/tools/audio_representation/tools/../pretrained_models/speechbrain_spkrec-ecapa-voxceleb/embedding_model.ckpt.\n",
      "INFO:speechbrain.pretrained.fetching:Fetch mean_var_norm_emb.ckpt: Using existing file/symlink in /Users/fabiocat/Documents/git/fab/tools/audio_representation/tools/../pretrained_models/speechbrain_spkrec-ecapa-voxceleb/mean_var_norm_emb.ckpt.\n",
      "INFO:speechbrain.pretrained.fetching:Fetch classifier.ckpt: Using existing file/symlink in /Users/fabiocat/Documents/git/fab/tools/audio_representation/tools/../pretrained_models/speechbrain_spkrec-ecapa-voxceleb/classifier.ckpt.\n",
      "INFO:speechbrain.pretrained.fetching:Fetch label_encoder.txt: Using existing file/symlink in /Users/fabiocat/Documents/git/fab/tools/audio_representation/tools/../pretrained_models/speechbrain_spkrec-ecapa-voxceleb/label_encoder.ckpt.\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
      "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /Users/fabiocat/Documents/git/fab/tools/audio_representation/tools/../pretrained_models/speechbrain_spkrec-ecapa-voxceleb/label_encoder.ckpt\n"
     ]
    }
   ],
   "source": [
    "audio_repr = AudioRepresentation(model_name=\"EcapaTDNN\")\n",
    "def extract_embeddings(input_waveform):\n",
    "    raw_encoder_response, filtered_encoder_response = audio_repr.contextual_encoding(input_waveform)\n",
    "    return filtered_encoder_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_to_embeddings(path_to_audio_folder):\n",
    "    file_details = []\n",
    "    for file_name in os.listdir(path_to_audio_folder):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            file_path = os.path.join(path_to_audio_folder, file_name)\n",
    "            waveform = load_audio(file_path)\n",
    "            speaker = file_name[:2]\n",
    "            file_details.append([file_path, file_name, speaker, waveform.squeeze()])\n",
    "    df = pd.DataFrame(file_details, columns=[\"Path\", \"Name\", \"Speaker\", \"Waveform\"])\n",
    "    df = pd.DataFrame(df.groupby('Speaker')['Waveform'].agg(lambda x: np.concatenate(x.values)), columns=['Waveform']).reset_index()\n",
    "    all_embeddings = []\n",
    "    for index, row in df.iterrows():\n",
    "        waveform = row['Waveform']\n",
    "        embeddings = extract_embeddings(torch.tensor(waveform))\n",
    "        all_embeddings.append(embeddings.squeeze())\n",
    "    df['Embeddings'] = all_embeddings\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T03:57:45.646562Z",
     "start_time": "2023-07-12T03:57:45.644966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Waveform</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03</td>\n",
       "      <td>[-0.0035095215, -0.0034179688, -0.0035095215, ...</td>\n",
       "      <td>[tensor(15.4843), tensor(16.0624), tensor(22.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08</td>\n",
       "      <td>[0.0, 0.0, -3.0517578e-05, -3.0517578e-05, 0.0...</td>\n",
       "      <td>[tensor(-18.8081), tensor(-34.4952), tensor(-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09</td>\n",
       "      <td>[-0.002166748, -0.0019836426, -0.0012512207, -...</td>\n",
       "      <td>[tensor(20.8529), tensor(37.2469), tensor(5.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>[0.0012207031, 0.0009765625, 0.0, 0.0, 0.00073...</td>\n",
       "      <td>[tensor(15.5112), tensor(2.7777), tensor(0.929...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>[0.00036621094, -0.00036621094, -0.00036621094...</td>\n",
       "      <td>[tensor(33.6959), tensor(4.3437), tensor(34.80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>[0.0, -0.00021362305, -0.00045776367, 0.0, 0.0...</td>\n",
       "      <td>[tensor(33.4371), tensor(-14.1550), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>[0.0015869141, 0.00024414062, -0.0005187988, -...</td>\n",
       "      <td>[tensor(14.6202), tensor(22.2819), tensor(-17....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>[0.0, 0.0, -3.0517578e-05, 9.1552734e-05, 0.0,...</td>\n",
       "      <td>[tensor(19.4504), tensor(41.1622), tensor(-1.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>[-0.00045776367, -0.00045776367, -0.0004577636...</td>\n",
       "      <td>[tensor(13.0594), tensor(28.7624), tensor(23.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>[0.0013122559, 0.00076293945, 0.00045776367, 0...</td>\n",
       "      <td>[tensor(-1.8589), tensor(33.8221), tensor(11.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Speaker                                           Waveform  \\\n",
       "0      03  [-0.0035095215, -0.0034179688, -0.0035095215, ...   \n",
       "1      08  [0.0, 0.0, -3.0517578e-05, -3.0517578e-05, 0.0...   \n",
       "2      09  [-0.002166748, -0.0019836426, -0.0012512207, -...   \n",
       "3      10  [0.0012207031, 0.0009765625, 0.0, 0.0, 0.00073...   \n",
       "4      11  [0.00036621094, -0.00036621094, -0.00036621094...   \n",
       "5      12  [0.0, -0.00021362305, -0.00045776367, 0.0, 0.0...   \n",
       "6      13  [0.0015869141, 0.00024414062, -0.0005187988, -...   \n",
       "7      14  [0.0, 0.0, -3.0517578e-05, 9.1552734e-05, 0.0,...   \n",
       "8      15  [-0.00045776367, -0.00045776367, -0.0004577636...   \n",
       "9      16  [0.0013122559, 0.00076293945, 0.00045776367, 0...   \n",
       "\n",
       "                                          Embeddings  \n",
       "0  [tensor(15.4843), tensor(16.0624), tensor(22.2...  \n",
       "1  [tensor(-18.8081), tensor(-34.4952), tensor(-3...  \n",
       "2  [tensor(20.8529), tensor(37.2469), tensor(5.14...  \n",
       "3  [tensor(15.5112), tensor(2.7777), tensor(0.929...  \n",
       "4  [tensor(33.6959), tensor(4.3437), tensor(34.80...  \n",
       "5  [tensor(33.4371), tensor(-14.1550), tensor(-0....  \n",
       "6  [tensor(14.6202), tensor(22.2819), tensor(-17....  \n",
       "7  [tensor(19.4504), tensor(41.1622), tensor(-1.1...  \n",
       "8  [tensor(13.0594), tensor(28.7624), tensor(23.9...  \n",
       "9  [tensor(-1.8589), tensor(33.8221), tensor(11.1...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = process_files_to_embeddings(audio_folder_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_audio_files_in_folder(tool_name, path_to_audio_folder, path_to_anonymized_audio_folder, target_speaker_file_path):\n",
    "    source_files = []\n",
    "    target_files = []\n",
    "    output_files = []\n",
    "    anonymizer = VoiceAnonymizer()\n",
    "    for file_name in os.listdir(path_to_audio_folder):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            file_path = os.path.join(path_to_audio_folder, file_name)\n",
    "            anonymized_file_path = file_path.replace(path_to_audio_folder, path_to_anonymized_audio_folder)\n",
    "            if not os.path.exists(anonymized_file_path):\n",
    "                pathlib.Path(os.path.dirname(anonymized_file_path)).mkdir(parents=True, exist_ok=True)\n",
    "                source_files.append(file_path)\n",
    "                target_files.append(target_speaker_file_path)\n",
    "                output_files.append(anonymized_file_path)\n",
    "                \n",
    "    if len(source_files) > 0:\n",
    "        anonymizer.anonymize(method=tool_name, source_files=source_files, target_files=target_files, output_files=output_files)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymize_audio_files_in_folder(tool_name, audio_folder_path, anonymized_audio_folder_path, target_speaker_file_path)\n",
    "anonymized_df = process_files_to_embeddings(anonymized_audio_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Waveform</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03</td>\n",
       "      <td>[-0.005126953, -0.0050964355, -0.005218506, -0...</td>\n",
       "      <td>[tensor(23.6612), tensor(-67.2823), tensor(-4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08</td>\n",
       "      <td>[-0.0018005371, -0.0018920898, -0.001953125, -...</td>\n",
       "      <td>[tensor(21.1716), tensor(-60.5933), tensor(-4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09</td>\n",
       "      <td>[0.0008544922, 0.0007019043, 0.00048828125, -6...</td>\n",
       "      <td>[tensor(25.8820), tensor(-59.6149), tensor(-3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>[-0.002532959, -0.0021362305, -0.0020446777, -...</td>\n",
       "      <td>[tensor(19.7992), tensor(-58.0896), tensor(-11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>[-0.0048217773, -0.004760742, -0.0047912598, -...</td>\n",
       "      <td>[tensor(24.2135), tensor(-62.0182), tensor(-3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>[-0.001373291, -0.0015258789, -0.0015563965, -...</td>\n",
       "      <td>[tensor(25.1391), tensor(-62.8612), tensor(-8....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>[-0.015136719, -0.01449585, -0.014587402, -0.0...</td>\n",
       "      <td>[tensor(20.0020), tensor(-63.5255), tensor(-4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>[0.0012817383, 0.0012512207, 0.0009765625, 0.0...</td>\n",
       "      <td>[tensor(21.3373), tensor(-63.7898), tensor(-2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>[-0.0011901855, -0.0010986328, -0.0009765625, ...</td>\n",
       "      <td>[tensor(23.0642), tensor(-61.5480), tensor(-6....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>[0.0032043457, 0.0028381348, 0.0028076172, 0.0...</td>\n",
       "      <td>[tensor(24.5440), tensor(-58.2845), tensor(-2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Speaker                                           Waveform  \\\n",
       "0      03  [-0.005126953, -0.0050964355, -0.005218506, -0...   \n",
       "1      08  [-0.0018005371, -0.0018920898, -0.001953125, -...   \n",
       "2      09  [0.0008544922, 0.0007019043, 0.00048828125, -6...   \n",
       "3      10  [-0.002532959, -0.0021362305, -0.0020446777, -...   \n",
       "4      11  [-0.0048217773, -0.004760742, -0.0047912598, -...   \n",
       "5      12  [-0.001373291, -0.0015258789, -0.0015563965, -...   \n",
       "6      13  [-0.015136719, -0.01449585, -0.014587402, -0.0...   \n",
       "7      14  [0.0012817383, 0.0012512207, 0.0009765625, 0.0...   \n",
       "8      15  [-0.0011901855, -0.0010986328, -0.0009765625, ...   \n",
       "9      16  [0.0032043457, 0.0028381348, 0.0028076172, 0.0...   \n",
       "\n",
       "                                          Embeddings  \n",
       "0  [tensor(23.6612), tensor(-67.2823), tensor(-4....  \n",
       "1  [tensor(21.1716), tensor(-60.5933), tensor(-4....  \n",
       "2  [tensor(25.8820), tensor(-59.6149), tensor(-3....  \n",
       "3  [tensor(19.7992), tensor(-58.0896), tensor(-11...  \n",
       "4  [tensor(24.2135), tensor(-62.0182), tensor(-3....  \n",
       "5  [tensor(25.1391), tensor(-62.8612), tensor(-8....  \n",
       "6  [tensor(20.0020), tensor(-63.5255), tensor(-4....  \n",
       "7  [tensor(21.3373), tensor(-63.7898), tensor(-2....  \n",
       "8  [tensor(23.0642), tensor(-61.5480), tensor(-6....  \n",
       "9  [tensor(24.5440), tensor(-58.2845), tensor(-2....  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anonymized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_score(embedding1, embedding2):\n",
    "        cos = torch.nn.CosineSimilarity(dim=-1)\n",
    "        similarity_score = cos(\n",
    "          torch.tensor(embedding1), \n",
    "          torch.tensor(embedding2)\n",
    "        )\n",
    "        return similarity_score.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eer_and_plot_verification_scores(df1, df2):\n",
    "    df_rows = []\n",
    "    for i, row1 in df1.iterrows():\n",
    "        for j, row2 in df2.iterrows():\n",
    "            s1 = row1['Speaker']\n",
    "            s2 = row2['Speaker']\n",
    "            e1 = row1['Embeddings']\n",
    "            e2 = row2['Embeddings']\n",
    "            cosine = compute_similarity_score(e1, e2)\n",
    "            same = s1==s2\n",
    "            df_rows = [s1, s2, e1, e2, cosine, same]\n",
    "\n",
    "                                     \n",
    "    print(df_rows)                            \n",
    "    input('a')\n",
    "           \n",
    "    df_pairs = pd.DataFrame(df_rows, columns=['Speaker 1', 'Speaker 2', 'Embeddings 1', 'Embeddings 2', 'Cosine distance', 'Same'])\n",
    "                                      \n",
    "    print(df_pairs)                            \n",
    "    input('a')\n",
    "    \n",
    "    positive_scores = df_pairs.loc[df_pairs['Same']==True]['Cosine distance'].values\n",
    "    negative_scores = df_pairs.loc[df_pairs['Same']==False]['Cosine distance'].values\n",
    "    eer, threshold = EER(torch.tensor(positive_scores), torch.tensor(negative_scores))\n",
    "    ax = sns.histplot(pairs_df, x='score', hue='label', stat='percent', common_norm=False)\n",
    "    ax.set_title(f'EER={round(eer, 4)} - Thresh={round(threshold, 4)}')\n",
    "    plt.axvline(x=[threshold], color='red', ls='--');\n",
    "    \n",
    "    # Show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16', '16', tensor([ -1.8589,  33.8221,  11.1322,   5.0038,  26.2954,   1.7196,  20.5756,\n",
      "         -8.0619, -24.1114,   8.2745,  -0.3052,  -3.7752, -21.5667,   6.9735,\n",
      "         -4.6047,  21.1282, -25.8671,  24.2125,   7.8221,  27.1022,  18.6943,\n",
      "        -14.7462, -22.5018,  -6.0401,  -4.6637, -21.0503, -20.8729, -13.8275,\n",
      "        -23.0265,  26.9956,   3.8421,  32.0135,  -9.8570, -14.4337,  27.5602,\n",
      "        -21.1562,  22.5684,  41.7198, -12.3433, -16.0436, -38.9267, -26.1178,\n",
      "          7.9296,   6.1755, -14.3315,   1.4976, -11.2418, -34.6953,  25.7681,\n",
      "        -33.6675,  45.5480,   7.5088,  27.7682,  -7.1959,   4.1995,  -3.2193,\n",
      "        -12.2359,  -3.8152,  10.0734,   4.5181,  18.0249,  14.2579, -17.6877,\n",
      "          2.3471,  -6.5354,   0.2849,   0.6662,  17.6339,   1.2249, -14.7638,\n",
      "        -15.2178,   9.4910,  12.4592,   5.3038, -10.6045,  -1.0934, -21.0426,\n",
      "        -24.0690,  -0.2459,  -3.4637,  -8.3764,   0.8177,  24.2244, -22.8897,\n",
      "         31.1636,  15.8667,  20.7510,   1.6165,  37.6504,  20.6424,  27.2611,\n",
      "          0.4010,   0.0852, -12.0676,  24.0915, -12.5687,  17.0569,  -0.5169,\n",
      "         23.4949,  13.3086,  12.0626,   7.4120,   6.2361, -12.0192,   8.8735,\n",
      "        -12.2711,  -8.1274, -16.5215, -12.2550,   3.8968, -13.3180, -36.1752,\n",
      "         -7.4525, -23.9039,  -6.6975,  17.7913,  21.0276,  -4.8195,  49.5673,\n",
      "         -5.7240, -25.7319,  30.6285,  -0.0845,  16.9326, -14.5978,  13.4541,\n",
      "          6.8166,   6.1194,   2.8238, -34.0826,  17.1131,  15.8383,  11.7981,\n",
      "         -1.3404,  -5.8624, -13.3615,  29.1582,  -4.6624, -13.1718,  12.0786,\n",
      "        -16.0075, -12.4978, -19.3188,  11.0580, -57.1893,  -2.4675,   5.4322,\n",
      "         11.3221, -11.8517,  -9.8724, -36.6062,  20.1568,   9.0244,  -9.5393,\n",
      "         23.6640,  16.5106, -14.8362,  -0.2070,  21.7607,  20.1849,   2.3171,\n",
      "         -3.3331, -20.9017,  -7.4545, -36.4264, -49.8372,   4.7348, -14.2963,\n",
      "         18.9756, -13.4781, -22.3498,  27.1994,  -0.6638,   0.8674, -14.3389,\n",
      "        -14.4060,  -4.9995,  14.7615, -18.1386,  20.9549,   5.4032, -11.8344,\n",
      "         -4.8851,   4.3319, -12.1705,  26.2459,   2.8318,  -1.7224, -32.8606,\n",
      "         -3.7217,  12.8347,   4.7573]), tensor([ -1.8589,  33.8221,  11.1322,   5.0038,  26.2954,   1.7196,  20.5756,\n",
      "         -8.0619, -24.1114,   8.2745,  -0.3052,  -3.7752, -21.5667,   6.9735,\n",
      "         -4.6047,  21.1282, -25.8671,  24.2125,   7.8221,  27.1022,  18.6943,\n",
      "        -14.7462, -22.5018,  -6.0401,  -4.6637, -21.0503, -20.8729, -13.8275,\n",
      "        -23.0265,  26.9956,   3.8421,  32.0135,  -9.8570, -14.4337,  27.5602,\n",
      "        -21.1562,  22.5684,  41.7198, -12.3433, -16.0436, -38.9267, -26.1178,\n",
      "          7.9296,   6.1755, -14.3315,   1.4976, -11.2418, -34.6953,  25.7681,\n",
      "        -33.6675,  45.5480,   7.5088,  27.7682,  -7.1959,   4.1995,  -3.2193,\n",
      "        -12.2359,  -3.8152,  10.0734,   4.5181,  18.0249,  14.2579, -17.6877,\n",
      "          2.3471,  -6.5354,   0.2849,   0.6662,  17.6339,   1.2249, -14.7638,\n",
      "        -15.2178,   9.4910,  12.4592,   5.3038, -10.6045,  -1.0934, -21.0426,\n",
      "        -24.0690,  -0.2459,  -3.4637,  -8.3764,   0.8177,  24.2244, -22.8897,\n",
      "         31.1636,  15.8667,  20.7510,   1.6165,  37.6504,  20.6424,  27.2611,\n",
      "          0.4010,   0.0852, -12.0676,  24.0915, -12.5687,  17.0569,  -0.5169,\n",
      "         23.4949,  13.3086,  12.0626,   7.4120,   6.2361, -12.0192,   8.8735,\n",
      "        -12.2711,  -8.1274, -16.5215, -12.2550,   3.8968, -13.3180, -36.1752,\n",
      "         -7.4525, -23.9039,  -6.6975,  17.7913,  21.0276,  -4.8195,  49.5673,\n",
      "         -5.7240, -25.7319,  30.6285,  -0.0845,  16.9326, -14.5978,  13.4541,\n",
      "          6.8166,   6.1194,   2.8238, -34.0826,  17.1131,  15.8383,  11.7981,\n",
      "         -1.3404,  -5.8624, -13.3615,  29.1582,  -4.6624, -13.1718,  12.0786,\n",
      "        -16.0075, -12.4978, -19.3188,  11.0580, -57.1893,  -2.4675,   5.4322,\n",
      "         11.3221, -11.8517,  -9.8724, -36.6062,  20.1568,   9.0244,  -9.5393,\n",
      "         23.6640,  16.5106, -14.8362,  -0.2070,  21.7607,  20.1849,   2.3171,\n",
      "         -3.3331, -20.9017,  -7.4545, -36.4264, -49.8372,   4.7348, -14.2963,\n",
      "         18.9756, -13.4781, -22.3498,  27.1994,  -0.6638,   0.8674, -14.3389,\n",
      "        -14.4060,  -4.9995,  14.7615, -18.1386,  20.9549,   5.4032, -11.8344,\n",
      "         -4.8851,   4.3319, -12.1705,  26.2459,   2.8318,  -1.7224, -32.8606,\n",
      "         -3.7217,  12.8347,   4.7573]), 1.0, True]\n"
     ]
    }
   ],
   "source": [
    "compute_eer_and_plot_verification_scores(df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Waveform</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03</td>\n",
       "      <td>[-0.0035095215, -0.0034179688, -0.0035095215, ...</td>\n",
       "      <td>[tensor(15.4843), tensor(16.0624), tensor(22.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08</td>\n",
       "      <td>[0.0, 0.0, -3.0517578e-05, -3.0517578e-05, 0.0...</td>\n",
       "      <td>[tensor(-18.8081), tensor(-34.4952), tensor(-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09</td>\n",
       "      <td>[-0.002166748, -0.0019836426, -0.0012512207, -...</td>\n",
       "      <td>[tensor(20.8529), tensor(37.2469), tensor(5.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>[0.0012207031, 0.0009765625, 0.0, 0.0, 0.00073...</td>\n",
       "      <td>[tensor(15.5112), tensor(2.7777), tensor(0.929...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>[0.00036621094, -0.00036621094, -0.00036621094...</td>\n",
       "      <td>[tensor(33.6959), tensor(4.3437), tensor(34.80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>[0.0, -0.00021362305, -0.00045776367, 0.0, 0.0...</td>\n",
       "      <td>[tensor(33.4371), tensor(-14.1550), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>[0.0015869141, 0.00024414062, -0.0005187988, -...</td>\n",
       "      <td>[tensor(14.6202), tensor(22.2819), tensor(-17....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>[0.0, 0.0, -3.0517578e-05, 9.1552734e-05, 0.0,...</td>\n",
       "      <td>[tensor(19.4504), tensor(41.1622), tensor(-1.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>[-0.00045776367, -0.00045776367, -0.0004577636...</td>\n",
       "      <td>[tensor(13.0594), tensor(28.7624), tensor(23.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>[0.0013122559, 0.00076293945, 0.00045776367, 0...</td>\n",
       "      <td>[tensor(-1.8589), tensor(33.8221), tensor(11.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Speaker                                           Waveform  \\\n",
       "0      03  [-0.0035095215, -0.0034179688, -0.0035095215, ...   \n",
       "1      08  [0.0, 0.0, -3.0517578e-05, -3.0517578e-05, 0.0...   \n",
       "2      09  [-0.002166748, -0.0019836426, -0.0012512207, -...   \n",
       "3      10  [0.0012207031, 0.0009765625, 0.0, 0.0, 0.00073...   \n",
       "4      11  [0.00036621094, -0.00036621094, -0.00036621094...   \n",
       "5      12  [0.0, -0.00021362305, -0.00045776367, 0.0, 0.0...   \n",
       "6      13  [0.0015869141, 0.00024414062, -0.0005187988, -...   \n",
       "7      14  [0.0, 0.0, -3.0517578e-05, 9.1552734e-05, 0.0,...   \n",
       "8      15  [-0.00045776367, -0.00045776367, -0.0004577636...   \n",
       "9      16  [0.0013122559, 0.00076293945, 0.00045776367, 0...   \n",
       "\n",
       "                                          Embeddings  \n",
       "0  [tensor(15.4843), tensor(16.0624), tensor(22.2...  \n",
       "1  [tensor(-18.8081), tensor(-34.4952), tensor(-3...  \n",
       "2  [tensor(20.8529), tensor(37.2469), tensor(5.14...  \n",
       "3  [tensor(15.5112), tensor(2.7777), tensor(0.929...  \n",
       "4  [tensor(33.6959), tensor(4.3437), tensor(34.80...  \n",
       "5  [tensor(33.4371), tensor(-14.1550), tensor(-0....  \n",
       "6  [tensor(14.6202), tensor(22.2819), tensor(-17....  \n",
       "7  [tensor(19.4504), tensor(41.1622), tensor(-1.1...  \n",
       "8  [tensor(13.0594), tensor(28.7624), tensor(23.9...  \n",
       "9  [tensor(-1.8589), tensor(33.8221), tensor(11.1...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anonymized[\"Path\"]\n",
    "df_anonymized[\"Name\"]\n",
    "df_anonymized[\"Speaker\"]\n",
    "df_anonymized[\"Signal\"]\n",
    "df_anonymized[\"Embeddings\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
